{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635932a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro JSON simple guardado: features_registry_num.json\n",
      "\n",
      "✅ Todos los archivos XLSX generados correctamente.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------- IMPORTS ---------------------------\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------- CONFIGURACIÓN BÁSICA -------------------\n",
    "base_power = \"Powerdata_filtrado\"                # Ruta a tus NPZ TF reales\n",
    "base_temporal = \"power_data_temporal_fil\"        # Ruta a NPZ temporales\n",
    "output_features_xlsx = \"features_completas.xlsx\"\n",
    "output_features_original_xlsx = \"features_completas_original.xlsx\"\n",
    "output_dict_xlsx = \"features_diccionario.xlsx\"\n",
    "REGISTRY_PATH = \"features_registry_num.json\"\n",
    "EPS = 1e-12\n",
    "\n",
    "# ---------------------- BANDAS DE FRECUENCIA -------------------\n",
    "band_plan = [\n",
    "    (10,    50,    1),\n",
    "    (50,    100,   1),\n",
    "    (100,   300,   4),\n",
    "    (300,   800,   5),\n",
    "    (800,   1500,  7),\n",
    "    (1500,  3000,  6),\n",
    "    (3000,  5000,  0),\n",
    "    (5000,  11025, 0),\n",
    "]\n",
    "\n",
    "def construir_bandas(plan):\n",
    "    edges = []\n",
    "    for i, (f0, f1, n) in enumerate(plan):\n",
    "        sub = np.linspace(float(f0), float(f1), int(n) + 1)\n",
    "        if i > 0:\n",
    "            sub = sub[1:]  # evitar duplicar borde\n",
    "        edges.extend(sub.tolist())\n",
    "    return np.array(edges, dtype=float)\n",
    "\n",
    "band_edges = construir_bandas(band_plan)\n",
    "assert len(band_edges) - 1 == 24, f\"Esperaba 36 bandas, obtuve {len(band_edges)-1}\"\n",
    "\n",
    "def obtener_rangos(bordes):\n",
    "    return [(bordes[i], bordes[i + 1]) for i in range(len(bordes) - 1)]\n",
    "\n",
    "band_ranges = obtener_rangos(band_edges)   # [(f0,f1), ...] 36 bandas\n",
    "\n",
    "# ------------------- DEFINICIÓN DE FEATURES -------------------\n",
    "GLOBAL_FEATURE_NAMES = [\n",
    "    # temporales (1–9)\n",
    "    \"mean_time\",\n",
    "    \"std_time\",\n",
    "    \"entropy_time\",\n",
    "    \"energy_time\",\n",
    "    \"skewness_time\",\n",
    "    \"kurtosis_time\",\n",
    "    \"time_peak_1\",\n",
    "    \"time_peak_2\",\n",
    "    \"duration_time\",\n",
    "\n",
    "    # TF / frecuencia global (10–17)\n",
    "    \"tf_energy_total\",\n",
    "    \"freq_centroid\",\n",
    "    \"freq_max\",\n",
    "    \"spectral_entropy\",\n",
    "    \"spectral_rolloff70\",\n",
    "    \"low_high_ratio\",\n",
    "    \"tf_energy_mean\",\n",
    "    \"tf_entropy_2d\",\n",
    "]\n",
    "\n",
    "# 6 features por banda (todas según el PDF actualizado)\n",
    "BAND_METRICS = [\n",
    "    \"energy\",         # E_B\n",
    "    \"energy_norm\",    # E_B / sum(E_B)\n",
    "    \"entropy_time\",   # entropía temporal dentro de la banda\n",
    "    \"std_time\",       # desviación estándar temporal W_B(t)\n",
    "    \"freq_dom\",       # frecuencia dominante en la banda\n",
    "    \"freq_70\",        # frecuencia donde se acumula el 70% de la energía de la banda\n",
    "]\n",
    "\n",
    "# nombres finales de features por banda\n",
    "BAND_FEATURE_NAMES = []\n",
    "for (f0, f1) in band_ranges:\n",
    "    label = f\"{int(round(f0))}_{int(round(f1))}\"  # por ej. \"1500_1750\"\n",
    "    for metric in BAND_METRICS:\n",
    "        BAND_FEATURE_NAMES.append(f\"band_{label}_{metric}\")\n",
    "\n",
    "ALL_FEATURE_NAMES = GLOBAL_FEATURE_NAMES + BAND_FEATURE_NAMES\n",
    "assert len(ALL_FEATURE_NAMES) == 161, f\"Se esperaban 233 features, hay {len(ALL_FEATURE_NAMES)}\"\n",
    "\n",
    "# ---------------------- FEATURES TEMPORALES ----------------------\n",
    "def features_temporales(signal):\n",
    "    \"\"\"\n",
    "    Features 1–9 (señal temporal x[t]):\n",
    "    - mean_time\n",
    "    - std_time\n",
    "    - entropy_time\n",
    "    - energy_time\n",
    "    - skewness_time\n",
    "    - kurtosis_time\n",
    "    - time_peak_1\n",
    "    - time_peak_2\n",
    "    - duration_time\n",
    "    \"\"\"\n",
    "    feats = {}\n",
    "    x = np.asarray(signal, dtype=float)\n",
    "    N = len(x)\n",
    "\n",
    "    if N == 0:\n",
    "        for name in GLOBAL_FEATURE_NAMES[:9]:\n",
    "            feats[name] = 0.0\n",
    "        feats[\"time_peak_1\"] = 0\n",
    "        feats[\"time_peak_2\"] = 0\n",
    "        feats[\"duration_time\"] = 0\n",
    "        return feats\n",
    "\n",
    "    mu = np.mean(x)\n",
    "    sigma = np.std(x)\n",
    "    feats[\"mean_time\"] = float(mu)\n",
    "    feats[\"std_time\"] = float(sigma)\n",
    "\n",
    "    # Entropía temporal (p_i = |x[i]| / sum|x|)\n",
    "    ax = np.abs(x)\n",
    "    s = ax.sum()\n",
    "    if s > 0:\n",
    "        p = ax / s\n",
    "        mask = p > 0\n",
    "        feats[\"entropy_time\"] = float(-(p[mask] * np.log2(p[mask] + EPS)).sum())\n",
    "    else:\n",
    "        feats[\"entropy_time\"] = 0.0\n",
    "\n",
    "    # Energía temporal (x^2)\n",
    "    feats[\"energy_time\"] = float(np.sum(x**2))\n",
    "\n",
    "    # Skewness y kurtosis\n",
    "    feats[\"skewness_time\"] = float(np.mean((x - mu)**3) / (sigma**3 + EPS))\n",
    "    feats[\"kurtosis_time\"] = float(np.mean((x - mu)**4) / (sigma**4 + EPS))\n",
    "\n",
    "    # Dos picos temporales más intensos (índices)\n",
    "    if N >= 2:\n",
    "        idx_top2 = np.argpartition(np.abs(x), -2)[-2:]\n",
    "        idx_top2.sort()\n",
    "        feats[\"time_peak_1\"] = int(idx_top2[0])\n",
    "        feats[\"time_peak_2\"] = int(idx_top2[1])\n",
    "    else:\n",
    "        feats[\"time_peak_1\"] = 0\n",
    "        feats[\"time_peak_2\"] = 0\n",
    "\n",
    "    # Duración (número de muestras)\n",
    "    feats[\"duration_time\"] = int(N)\n",
    "    return feats\n",
    "\n",
    "# ---------------------- FEATURES TF / FRECUENCIA (CWT) ----------------------\n",
    "def features_power(power, freqs):\n",
    "    \"\"\"\n",
    "    Features 10–17 globales + 6*36 features por banda.\n",
    "\n",
    "    power: matriz |W(a,t)|   (escalas x tiempo)\n",
    "    freqs: vector de frecuencia equivalente por escala (Hz), \n",
    "           mismo tamaño que número de filas de power.\n",
    "    \"\"\"\n",
    "    feats = {}\n",
    "    P = np.asarray(power, dtype=float)   # CWT magnitudes\n",
    "    F = np.asarray(freqs, dtype=float)\n",
    "\n",
    "    if P.size == 0 or F.size == 0:\n",
    "        for name in GLOBAL_FEATURE_NAMES[9:]:\n",
    "            feats[name] = 0.0\n",
    "        for name in BAND_FEATURE_NAMES:\n",
    "            feats[name] = 0.0\n",
    "        return feats\n",
    "\n",
    "    # ---------- 10. Energía total TF ----------\n",
    "    feats[\"tf_energy_total\"] = float(np.sum(P))\n",
    "\n",
    "    # ---------- 16. Energía media 2D ----------\n",
    "    feats[\"tf_energy_mean\"] = float(np.mean(P))\n",
    "\n",
    "    # ---------- 17. Entropía 2D ----------\n",
    "    total_P = np.sum(P)\n",
    "    if total_P > 0:\n",
    "        q = (P / (total_P + EPS)).flatten()\n",
    "        mask = q > 0\n",
    "        feats[\"tf_entropy_2d\"] = float(-(q[mask] * np.log2(q[mask] + EPS)).sum())\n",
    "    else:\n",
    "        feats[\"tf_entropy_2d\"] = 0.0\n",
    "\n",
    "    # Energía por escala (para centroide, fmax, entropía espectral, rolloff, ratio)\n",
    "    Ef = np.sum(P, axis=1)   # sum sobre tiempo\n",
    "    Ef_sum = np.sum(Ef)\n",
    "\n",
    "    if Ef_sum > 0:\n",
    "        # ---------- 11. Frecuencia media (centroide) ----------\n",
    "        feats[\"freq_centroid\"] = float(np.sum(F * Ef) / (Ef_sum + EPS))\n",
    "\n",
    "        # ---------- 12. Frecuencia de máxima energía ----------\n",
    "        feats[\"freq_max\"] = float(F[np.argmax(Ef)])\n",
    "\n",
    "        # ---------- 13. Entropía espectral global ----------\n",
    "        pf = Ef / (Ef_sum + EPS)\n",
    "        mask_pf = pf > 0\n",
    "        feats[\"spectral_entropy\"] = float(-(pf[mask_pf] * np.log2(pf[mask_pf] + EPS)).sum())\n",
    "\n",
    "        # ---------- 14. Rolloff 70% global ----------\n",
    "        cum_E = np.cumsum(Ef)\n",
    "        idx_roll = np.argmax(cum_E >= 0.7 * Ef_sum)\n",
    "        feats[\"spectral_rolloff70\"] = float(F[idx_roll])\n",
    "\n",
    "        # ---------- 15. Ratio <3kHz / ≥3kHz ----------\n",
    "        low_mask = F < 3000\n",
    "        high_mask = ~low_mask\n",
    "        E_low = np.sum(Ef[low_mask])\n",
    "        E_high = np.sum(Ef[high_mask])\n",
    "        feats[\"low_high_ratio\"] = float(E_low / (E_high + EPS))\n",
    "    else:\n",
    "        feats[\"freq_centroid\"] = 0.0\n",
    "        feats[\"freq_max\"] = 0.0\n",
    "        feats[\"spectral_entropy\"] = 0.0\n",
    "        feats[\"spectral_rolloff70\"] = 0.0\n",
    "        feats[\"low_high_ratio\"] = 0.0\n",
    "\n",
    "    # ---------------------- FEATURES POR BANDA ----------------------\n",
    "    n_bands = len(band_ranges)\n",
    "\n",
    "    # Primero calculamos E_B y datos intermedios para cada banda\n",
    "    band_data = []  # lista de dicts para cada banda\n",
    "    for i, (f0, f1) in enumerate(band_ranges):\n",
    "        # última banda incluye el límite superior\n",
    "        if i < n_bands - 1:\n",
    "            idx = np.where((F >= f0) & (F < f1))[0]\n",
    "        else:\n",
    "            idx = np.where((F >= f0) & (F <= f1))[0]\n",
    "\n",
    "        label = f\"{int(round(f0))}_{int(round(f1))}\"\n",
    "\n",
    "        if idx.size == 0:\n",
    "            band_data.append({\n",
    "                \"label\": label,\n",
    "                \"E_B\": 0.0,\n",
    "                \"W_B\": None,\n",
    "                \"F_band\": None,\n",
    "                \"EfB\": None,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        B = P[idx, :]                    # (n_escalas_en_banda x T)\n",
    "        W_B = np.sum(B, axis=0)          # W_B(t) = sum_{a in B} |W(a,t)|\n",
    "        E_B = float(np.sum(W_B))         # energía total de la banda\n",
    "        F_band = F[idx]                  # frecuencias de las escalas en la banda\n",
    "        EfB = np.sum(B, axis=1)          # energía por \"frecuencia\" dentro de banda\n",
    "\n",
    "        band_data.append({\n",
    "            \"label\": label,\n",
    "            \"E_B\": E_B,\n",
    "            \"W_B\": W_B,\n",
    "            \"F_band\": F_band,\n",
    "            \"EfB\": EfB,\n",
    "        })\n",
    "\n",
    "    # Suma total de energía en bandas (para normalización)\n",
    "    total_E_bands = sum(d[\"E_B\"] for d in band_data)\n",
    "\n",
    "    # Ahora calculamos las 6 métricas por banda\n",
    "    for d in band_data:\n",
    "        label = d[\"label\"]\n",
    "        base = f\"band_{label}_\"\n",
    "        E_B = d[\"E_B\"]\n",
    "        W_B = d[\"W_B\"]\n",
    "        F_band = d[\"F_band\"]\n",
    "        EfB = d[\"EfB\"]\n",
    "\n",
    "        if (W_B is None) or (E_B <= 0):\n",
    "            # banda vacía o sin energía\n",
    "            feats[base + \"energy\"] = 0.0\n",
    "            feats[base + \"energy_norm\"] = 0.0\n",
    "            feats[base + \"entropy_time\"] = 0.0\n",
    "            feats[base + \"std_time\"] = 0.0\n",
    "            feats[base + \"freq_dom\"] = 0.0\n",
    "            feats[base + \"freq_70\"] = 0.0\n",
    "            continue\n",
    "\n",
    "        # 1) Energía en banda\n",
    "        feats[base + \"energy\"] = E_B\n",
    "\n",
    "        # 2) Energía normalizada en banda\n",
    "        if total_E_bands > 0:\n",
    "            feats[base + \"energy_norm\"] = float(E_B / (total_E_bands + EPS))\n",
    "        else:\n",
    "            feats[base + \"energy_norm\"] = 0.0\n",
    "\n",
    "        # 3) Entropía temporal dentro de la banda\n",
    "        p_t = W_B / (E_B + EPS)\n",
    "        mask_t = p_t > 0\n",
    "        H_B = -(p_t[mask_t] * np.log2(p_t[mask_t] + EPS)).sum()\n",
    "        feats[base + \"entropy_time\"] = float(H_B)\n",
    "\n",
    "        # 4) Desviación estándar temporal de la banda\n",
    "        mu_B = float(np.mean(W_B))\n",
    "        sigma_B = float(np.sqrt(np.mean((W_B - mu_B)**2)))\n",
    "        feats[base + \"std_time\"] = sigma_B\n",
    "\n",
    "        # 5) Frecuencia dominante en la banda (frecuencia con mayor energía integrada)\n",
    "        EfB_sum = np.sum(EfB)\n",
    "        if EfB_sum > 0:\n",
    "            idx_max = np.argmax(EfB)\n",
    "            freq_dom = float(F_band[idx_max])\n",
    "\n",
    "            # 6) Frecuencia donde se acumula el 70% de la energía de la banda\n",
    "            cumB = np.cumsum(EfB)\n",
    "            idx70 = np.argmax(cumB >= 0.7 * EfB_sum)\n",
    "            freq_70 = float(F_band[idx70])\n",
    "        else:\n",
    "            freq_dom = 0.0\n",
    "            freq_70 = 0.0\n",
    "\n",
    "        feats[base + \"freq_dom\"] = freq_dom\n",
    "        feats[base + \"freq_70\"] = freq_70\n",
    "\n",
    "    return feats\n",
    "\n",
    "# ----------------- RECORRIDO DE ARCHIVOS -----------------\n",
    "records = []\n",
    "\n",
    "for tipo in [\"pacientes\", \"sujetos\"]:\n",
    "    power_dir = os.path.join(base_power, tipo)\n",
    "    temp_dir = os.path.join(base_temporal, tipo)\n",
    "\n",
    "    if not os.path.exists(power_dir):\n",
    "        continue\n",
    "\n",
    "    for iddsi_folder in os.listdir(power_dir):\n",
    "        folder_tf = os.path.join(power_dir, iddsi_folder)\n",
    "        folder_temp = os.path.join(temp_dir, iddsi_folder)\n",
    "        if not os.path.isdir(folder_tf):\n",
    "            continue\n",
    "\n",
    "        for archivo in os.listdir(folder_tf):\n",
    "            if not archivo.endswith(\".npz\"):\n",
    "                continue\n",
    "\n",
    "            data_power = np.load(os.path.join(folder_tf, archivo))\n",
    "\n",
    "            # CWT magnitude / energy\n",
    "            power = data_power[\"cwt_mag\"].astype(float)\n",
    "            freqs = data_power[\"freqs\"].astype(float)\n",
    "\n",
    "            sujeto = str(data_power[\"sujeto\"])\n",
    "            iddsi = int(data_power[\"iddsi\"])\n",
    "            sorbo = int(data_power[\"sorbo\"])\n",
    "            t_ini = float(data_power[\"t_ini\"])\n",
    "            t_fin = float(data_power[\"t_fin\"])\n",
    "\n",
    "            file_temp = os.path.join(folder_temp, archivo)\n",
    "            if os.path.exists(file_temp):\n",
    "                data_temp = np.load(file_temp)\n",
    "                temporal_signal = data_temp[\"signal_fil\"].astype(float)\n",
    "            else:\n",
    "                temporal_signal = np.zeros(power.shape[1])\n",
    "\n",
    "            # features temporales y CWT\n",
    "            feats_t = features_temporales(temporal_signal)\n",
    "            feats_p = features_power(power, freqs)\n",
    "\n",
    "            merged = {**feats_t, **feats_p}\n",
    "            merged.update({\n",
    "                \"tipo\": tipo,\n",
    "                \"sujeto\": sujeto,\n",
    "                \"iddsi\": iddsi,\n",
    "                \"sorbo\": sorbo,\n",
    "                \"duracion\": float(t_fin - t_ini),\n",
    "                \"archivo\": archivo,\n",
    "            })\n",
    "\n",
    "            records.append(merged)\n",
    "\n",
    "if not records:\n",
    "    raise RuntimeError(\"No se encontraron NPZ. Revisa tus carpetas.\")\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# ------------------------ MATRICES DE SALIDA ------------------------\n",
    "metadata_cols = [\"tipo\", \"sujeto\", \"iddsi\", \"sorbo\", \"duracion\", \"archivo\"]\n",
    "\n",
    "# Garantizar que todas las columnas de features existan\n",
    "for name in ALL_FEATURE_NAMES:\n",
    "    if name not in df.columns:\n",
    "        df[name] = 0.0\n",
    "\n",
    "df_original = df[metadata_cols + ALL_FEATURE_NAMES].copy()\n",
    "\n",
    "# ID → nombre\n",
    "id_to_name = {i + 1: name for i, name in enumerate(ALL_FEATURE_NAMES)}\n",
    "\n",
    "# Guardar JSON\n",
    "with open(REGISTRY_PATH, \"w\", encoding=\"utf-8\") as fh:\n",
    "    json.dump({str(k): v for k, v in id_to_name.items()}, fh,\n",
    "              ensure_ascii=False, indent=2)\n",
    "print(\"Registro JSON simple guardado:\", REGISTRY_PATH)\n",
    "\n",
    "# Renombrar columnas de features a IDs numéricos\n",
    "rename_map = {name: str(i + 1) for i, name in enumerate(ALL_FEATURE_NAMES)}\n",
    "df_ids = df_original.rename(columns=rename_map)\n",
    "\n",
    "# ------------------------ GUARDAR XLSX ------------------------\n",
    "try:\n",
    "    try:\n",
    "        import xlsxwriter\n",
    "        engine = \"xlsxwriter\"\n",
    "    except Exception:\n",
    "        import openpyxl\n",
    "        engine = \"openpyxl\"\n",
    "\n",
    "    with pd.ExcelWriter(output_features_xlsx, engine=engine) as xw:\n",
    "        df_ids.to_excel(xw, index=False, sheet_name=\"features_ids\")\n",
    "\n",
    "    with pd.ExcelWriter(output_features_original_xlsx, engine=engine) as xw:\n",
    "        df_original.to_excel(xw, index=False, sheet_name=\"features_original\")\n",
    "\n",
    "    dict_rows = [{\"ID\": fid, \"Feature\": fname} for fid, fname in id_to_name.items()]\n",
    "    df_dict = pd.DataFrame(dict_rows).sort_values(by=\"ID\")\n",
    "    with pd.ExcelWriter(output_dict_xlsx, engine=engine) as xw:\n",
    "        df_dict.to_excel(xw, index=False, sheet_name=\"Diccionario\")\n",
    "\n",
    "    print(\"\\n Todos los archivos XLSX generados correctamente.\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error generando XLSX:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e04189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claves del archivo: ['signal_fil', 'sujeto', 'iddsi', 'sorbo', 'fs', 't_ini', 't_fin', 'downsample_factor', 'filtro_wavelet']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"power_data_temporal_fil/pacientes/IDDSI0/P1S1.npz\")\n",
    "print(\"Claves del archivo:\", data.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87d32c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivos XLSX por IDDSI generados con SOLO 'tipo' + features.\n",
      "✅ Excel unificado 'features_por_IDDSI.xlsx' generado SOLO con 'tipo' + features.\n"
     ]
    }
   ],
   "source": [
    "# -------------------- SEPARACIÓN EN 3 MATRICES POR IDDSI --------------------\n",
    "iddsi_targets = [0, 2, 4]\n",
    "split_prefix = \"features_IDDSI\"\n",
    "\n",
    "# SOLO features + tipo\n",
    "feature_cols = [c for c in df_ids.columns if c not in metadata_cols]\n",
    "cols_keep = [\"tipo\"] + feature_cols   # Dejamos tipo como único metadato útil\n",
    "\n",
    "# -------------------- EXPORTAR XLSX INDIVIDUALES --------------------\n",
    "for val in iddsi_targets:\n",
    "\n",
    "    # Filtrar filas por IDDSI\n",
    "    sub = df_ids[df_ids[\"iddsi\"] == val]\n",
    "\n",
    "    if sub.empty:\n",
    "        print(f\"⚠️ No hay registros para IDDSI={val}; no se genera archivo XLSX.\")\n",
    "        continue\n",
    "\n",
    "    # Mantener SOLO \"tipo\" + features\n",
    "    sub_clean = sub[cols_keep]\n",
    "\n",
    "    # Convertir a matriz (incluye columna tipo)\n",
    "    matrix = sub_clean.to_numpy()\n",
    "\n",
    "    # Guardar en XLSX SIN headers NI índice\n",
    "    filename = f\"{split_prefix}{val}.xlsx\"\n",
    "    with pd.ExcelWriter(filename, engine=\"xlsxwriter\") as writer:\n",
    "        pd.DataFrame(matrix).to_excel(writer, index=False, header=False, sheet_name=f\"IDDSI_{val}\")\n",
    "\n",
    "print(\"✅ Archivos XLSX por IDDSI generados con SOLO 'tipo' + features.\")\n",
    "\n",
    "# -------------------- EXCEL UNIFICADO --------------------\n",
    "try:\n",
    "    with pd.ExcelWriter(\"features_por_IDDSI.xlsx\", engine=\"xlsxwriter\") as xw:\n",
    "        for val in iddsi_targets:\n",
    "            sub = df_ids[df_ids[\"iddsi\"] == val]\n",
    "            if sub.empty:\n",
    "                continue\n",
    "\n",
    "            sub_clean = sub[cols_keep]\n",
    "            matrix = sub_clean.to_numpy()\n",
    "\n",
    "            pd.DataFrame(matrix).to_excel(\n",
    "                xw,\n",
    "                index=False,\n",
    "                header=False,\n",
    "                sheet_name=f\"IDDSI_{val}\"\n",
    "            )\n",
    "\n",
    "    print(\"✅ Excel unificado 'features_por_IDDSI.xlsx' generado SOLO con 'tipo' + features.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Error al crear Excel por IDDSI: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f4083",
   "metadata": {},
   "source": [
    "APLICAR Wilcoxon rank-sum test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e61675",
   "metadata": {},
   "source": [
    "No es necesario normalizar pero puede servir para probar con otros TEST estadisticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c68689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fernando.salamanca\\AppData\\Local\\Temp\\ipykernel_7652\\161652468.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_norm.insert(0, \"tipo\", tipo)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Matriz normalizada Min–Max guardada en: IDDSI0_minmax.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fernando.salamanca\\AppData\\Local\\Temp\\ipykernel_7652\\161652468.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_norm.insert(0, \"tipo\", tipo)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Matriz normalizada Min–Max guardada en: IDDSI2_minmax.xlsx\n",
      "✔ Matriz normalizada Min–Max guardada en: IDDSI4_minmax.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fernando.salamanca\\AppData\\Local\\Temp\\ipykernel_7652\\161652468.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_norm.insert(0, \"tipo\", tipo)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def normalizar_minmax(path_in, path_out):\n",
    "    # cargar matriz (sin header)\n",
    "    df = pd.read_excel(path_in, header=None)\n",
    "\n",
    "    # asignar nombres de columnas\n",
    "    df.columns = [\"tipo\"] + [f\"f{i}\" for i in range(1, df.shape[1])]\n",
    "\n",
    "    tipo = df[\"tipo\"]\n",
    "    X = df.drop(columns=[\"tipo\"]).astype(float)\n",
    "\n",
    "    # Min–Max: x' = (x - min) / (max - min)\n",
    "    X_min = X.min(axis=0)\n",
    "    X_max = X.max(axis=0)\n",
    "    X_norm = (X - X_min) / (X_max - X_min + 1e-12)\n",
    "\n",
    "    # reconstruir\n",
    "    df_norm = pd.DataFrame(X_norm, columns=X.columns)\n",
    "    df_norm.insert(0, \"tipo\", tipo)\n",
    "\n",
    "    # guardar sin header ni index\n",
    "    df_norm.to_excel(path_out, index=False, header=False)\n",
    "    print(f\"✔ Matriz normalizada Min–Max guardada en: {path_out}\")\n",
    "\n",
    "normalizar_minmax(\"features_IDDSI0.xlsx\", \"IDDSI0_minmax.xlsx\")\n",
    "normalizar_minmax(\"features_IDDSI2.xlsx\", \"IDDSI2_minmax.xlsx\")\n",
    "normalizar_minmax(\"features_IDDSI4.xlsx\", \"IDDSI4_minmax.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe7b8902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDDSI0 shape: (78, 162)\n",
      "IDDSI2 shape: (85, 162)\n",
      "IDDSI4 shape: (84, 162)\n",
      "        tipo         1         2         3         4         5         6  \\\n",
      "0  pacientes  0.545256  0.540855  0.509711  0.436656  0.596018  0.118797   \n",
      "1  pacientes  0.372540  0.873900  0.069792  0.429370  0.574819  0.102579   \n",
      "2  pacientes  0.000000  0.625789  0.113890  0.248278  0.715432  0.195645   \n",
      "3  pacientes  0.077033  0.200435  0.279025  0.039140  0.425240  0.015178   \n",
      "4  pacientes  0.524012  0.113030  0.948785  0.130428  0.430494  0.075512   \n",
      "\n",
      "          7         8         9  ...       152       153  154  155       156  \\\n",
      "0  0.169732  0.133006  0.343434  ...  0.719403  0.050355  0.0    0  0.291524   \n",
      "1  0.069751  0.028602  0.037808  ...  0.415397  0.074359  0.0    0  0.088455   \n",
      "2  0.081641  0.041019  0.046146  ...  0.413057  0.083441  0.0    0  0.078988   \n",
      "3  0.152162  0.114659  0.056505  ...  0.490103  0.025334  0.0    0  0.069488   \n",
      "4  0.425140  0.399712  1.000000  ...  0.947866  0.038039  0.0    0  0.335488   \n",
      "\n",
      "        157       158       159  160  161  \n",
      "0  0.109883  0.717784  0.044736    0    0  \n",
      "1  0.058288  0.432334  0.050656    0    0  \n",
      "2  0.087872  0.445342  0.044391    0    0  \n",
      "3  0.158716  0.490306  0.022730    0    0  \n",
      "4  0.188382  0.974650  0.022744    0    0  \n",
      "\n",
      "[5 rows x 162 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar las 3 matrices SIN encabezados\n",
    "df0 = pd.read_excel(\"IDDSI0_minmax.xlsx\", header=None)\n",
    "df2 = pd.read_excel(\"IDDSI2_minmax.xlsx\", header=None)\n",
    "df4 = pd.read_excel(\"IDDSI4_minmax.xlsx\", header=None)\n",
    "\n",
    "print(\"IDDSI0 shape:\", df0.shape)\n",
    "print(\"IDDSI2 shape:\", df2.shape)\n",
    "print(\"IDDSI4 shape:\", df4.shape)\n",
    "\n",
    "def poner_nombres(df):\n",
    "    n_cols = df.shape[1]\n",
    "    feature_names = [str(i) for i in range(1, n_cols)]  # \"1\",\"2\",...,\n",
    "    df.columns = [\"tipo\"] + feature_names\n",
    "    return df\n",
    "\n",
    "df0 = poner_nombres(df0)\n",
    "df2 = poner_nombres(df2)\n",
    "df4 = poner_nombres(df4)\n",
    "\n",
    "print(df0.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec268731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ranksums   \n",
    "\n",
    "def ranksum_por_matriz(df_iddsi):\n",
    "\n",
    "    # Separar grupos\n",
    "    df_pac = df_iddsi[df_iddsi[\"tipo\"] == \"pacientes\"]\n",
    "    df_san = df_iddsi[df_iddsi[\"tipo\"] == \"sujetos\"]\n",
    "\n",
    "    print(f\"n pacientes = {len(df_pac)}, n sanos = {len(df_san)}\")\n",
    "\n",
    "    feature_cols = [c for c in df_iddsi.columns if c != \"tipo\"]\n",
    "    resultados = []\n",
    "\n",
    "    for col in feature_cols:\n",
    "        x = df_pac[col].values\n",
    "        y = df_san[col].values\n",
    "\n",
    "        # Evitar errores si falta algún dato\n",
    "        if len(x) == 0 or len(y) == 0:\n",
    "            continue\n",
    "\n",
    "        # Test Wilcoxon rank-sum (según la doc de ranksums)\n",
    "        stat, p = ranksums(x, y)\n",
    "\n",
    "        resultados.append({\n",
    "            \"feature_ID\": col,\n",
    "            \"Z_statistic\": stat,         # ranksums entrega estadístico tipo Z\n",
    "            \"p_value\": p,\n",
    "            \"median_pacientes\": np.median(x),\n",
    "            \"median_sanos\": np.median(y),\n",
    "            \"mean_pacientes\": np.mean(x),\n",
    "            \"mean_sanos\": np.mean(y),\n",
    "            \"significativo_0_05\": p < 0.05\n",
    "        })\n",
    "\n",
    "    # Convertir a tabla ordenada por p-value\n",
    "    res_df = pd.DataFrame(resultados)\n",
    "    res_df = res_df.sort_values(\"p_value\").reset_index(drop=True)\n",
    "    return res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cee5bb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n pacientes = 33, n sanos = 45\n",
      "n pacientes = 45, n sanos = 40\n",
      "n pacientes = 39, n sanos = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_ID</th>\n",
       "      <th>Z_statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>median_pacientes</th>\n",
       "      <th>median_sanos</th>\n",
       "      <th>mean_pacientes</th>\n",
       "      <th>mean_sanos</th>\n",
       "      <th>significativo_0_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>5.376898</td>\n",
       "      <td>7.578013e-08</td>\n",
       "      <td>0.203041</td>\n",
       "      <td>0.122390</td>\n",
       "      <td>0.287373</td>\n",
       "      <td>0.114797</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>4.309590</td>\n",
       "      <td>1.635572e-05</td>\n",
       "      <td>0.087098</td>\n",
       "      <td>0.047921</td>\n",
       "      <td>0.189834</td>\n",
       "      <td>0.059912</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>-4.188509</td>\n",
       "      <td>2.807929e-05</td>\n",
       "      <td>0.392718</td>\n",
       "      <td>0.592689</td>\n",
       "      <td>0.369632</td>\n",
       "      <td>0.634751</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4.139180</td>\n",
       "      <td>3.485495e-05</td>\n",
       "      <td>0.098697</td>\n",
       "      <td>0.054044</td>\n",
       "      <td>0.190306</td>\n",
       "      <td>0.064071</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>4.022583</td>\n",
       "      <td>5.756328e-05</td>\n",
       "      <td>0.084641</td>\n",
       "      <td>0.045608</td>\n",
       "      <td>0.144834</td>\n",
       "      <td>0.053295</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_ID  Z_statistic       p_value  median_pacientes  median_sanos  \\\n",
       "0         16     5.376898  7.578013e-08          0.203041      0.122390   \n",
       "1        123     4.309590  1.635572e-05          0.087098      0.047921   \n",
       "2         35    -4.188509  2.807929e-05          0.392718      0.592689   \n",
       "3        117     4.139180  3.485495e-05          0.098697      0.054044   \n",
       "4         24     4.022583  5.756328e-05          0.084641      0.045608   \n",
       "\n",
       "   mean_pacientes  mean_sanos  significativo_0_05  \n",
       "0        0.287373    0.114797                True  \n",
       "1        0.189834    0.059912                True  \n",
       "2        0.369632    0.634751                True  \n",
       "3        0.190306    0.064071                True  \n",
       "4        0.144834    0.053295                True  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res0 = ranksum_por_matriz(df0)\n",
    "res2 = ranksum_por_matriz(df2)\n",
    "res4 = ranksum_por_matriz(df4)\n",
    "\n",
    "res0.head()\n",
    "res2.head()\n",
    "res4.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8d5d7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Excel generado con features ordenados por p-value (más significativos arriba).\n"
     ]
    }
   ],
   "source": [
    "# Ordenar resultados por p-value ascendente (por si acaso)\n",
    "res0_sorted = res0.sort_values(by=\"p_value\", ascending=True)\n",
    "res2_sorted = res2.sort_values(by=\"p_value\", ascending=True)\n",
    "res4_sorted = res4.sort_values(by=\"p_value\", ascending=True)\n",
    "\n",
    "# Guardar Excel con orden aplicado\n",
    "with pd.ExcelWriter(\"Ranksum_por_IDDSI.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    res0_sorted.to_excel(writer, index=False, sheet_name=\"IDDSI_0\")\n",
    "    res2_sorted.to_excel(writer, index=False, sheet_name=\"IDDSI_2\")\n",
    "    res4_sorted.to_excel(writer, index=False, sheet_name=\"IDDSI_4\")\n",
    "\n",
    "print(\"✔ Excel generado con features ordenados por p-value (más significativos arriba).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dec1c4",
   "metadata": {},
   "source": [
    "mRMR test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bb6a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.selection import MRMR\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06285764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDDSI 0 - N° features significativos: 50\n",
      "IDDSI 2 - N° features significativos: 67\n",
      "IDDSI 4 - N° features significativos: 64\n"
     ]
    }
   ],
   "source": [
    "# Archivo con los resultados del RankSum\n",
    "ranksum_file = \"Ranksum_por_IDDSI.xlsx\"\n",
    "\n",
    "# Cargar todas las hojas\n",
    "dfs_ranksum = pd.read_excel(ranksum_file, sheet_name=None)\n",
    "\n",
    "# Listas de features significativos (feature_ID donde significativo_0_05 == True)\n",
    "sig_0 = dfs_ranksum[\"IDDSI_0\"].loc[\n",
    "    dfs_ranksum[\"IDDSI_0\"][\"significativo_0_05\"] == True, \"feature_ID\"\n",
    "].tolist()\n",
    "\n",
    "sig_2 = dfs_ranksum[\"IDDSI_2\"].loc[\n",
    "    dfs_ranksum[\"IDDSI_2\"][\"significativo_0_05\"] == True, \"feature_ID\"\n",
    "].tolist()\n",
    "\n",
    "sig_4 = dfs_ranksum[\"IDDSI_4\"].loc[\n",
    "    dfs_ranksum[\"IDDSI_4\"][\"significativo_0_05\"] == True, \"feature_ID\"\n",
    "].tolist()\n",
    "\n",
    "print(\"IDDSI 0 - N° features significativos:\", len(sig_0))\n",
    "print(\"IDDSI 2 - N° features significativos:\", len(sig_2))\n",
    "print(\"IDDSI 4 - N° features significativos:\", len(sig_4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2edc7a",
   "metadata": {},
   "source": [
    "funcion generica para no repetir por iddsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "459e0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_iddsi_mrmr(nombre_archivo_matriz, sig_features_ids, max_features=20):\n",
    "    \"\"\"\n",
    "    Procesa una matriz de features IDDSI con:\n",
    "    - Renombrado de columnas a '1', '2', ..., '233'\n",
    "    - Filtrado por RankSum (sig_features_ids)\n",
    "    - Split train/test\n",
    "    - Selección mRMR\n",
    "    \n",
    "    Retorna:\n",
    "        X_train_mrmr, X_test_mrmr, y_train, y_test, selected_features, mrmr_object\n",
    "    \"\"\"\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 1) Cargar matriz IDDSI\n",
    "    # ----------------------------------------------------------\n",
    "    df = pd.read_excel(nombre_archivo_matriz)\n",
    "    \n",
    "    # Etiquetas\n",
    "    y = df[\"pacientes\"]\n",
    "    \n",
    "    # Features\n",
    "    X = df.drop(columns=[\"pacientes\"])\n",
    "    \n",
    "    print(\"\\nForma original de X:\", X.shape)\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 2) Renombrar columnas a \"1\", \"2\", ..., \"N\"\n",
    "    # ----------------------------------------------------------\n",
    "    n_features = X.shape[1]\n",
    "    new_cols = [str(i) for i in range(1, n_features + 1)]\n",
    "    X.columns = new_cols\n",
    "    \n",
    "    print(\"Primeros nombres de columnas renombradas:\", X.columns[:10].tolist())\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 3) Filtrar features significativos del RankSum\n",
    "    # ----------------------------------------------------------\n",
    "    cols_sig = [str(i) for i in sig_features_ids]  # convertir IDs a strings\n",
    "    X_sig = X[cols_sig]\n",
    "    \n",
    "    print(\"Forma X_sig (solo significativos):\", X_sig.shape)\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 4) Train / Test split\n",
    "    # ----------------------------------------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_sig,\n",
    "        y,\n",
    "        test_size=0.3,\n",
    "        random_state=0,\n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "    print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 5) Crear y ejecutar mRMR\n",
    "    # ----------------------------------------------------------\n",
    "    mrmr_sel = MRMR(\n",
    "        variables=None,\n",
    "        method=\"FCQ\",      # método recomendado para comenzar\n",
    "        max_features=max_features,\n",
    "        regression=False,  # clasificación\n",
    "        random_state=0\n",
    "    )\n",
    "    \n",
    "    mrmr_sel.fit(X_train, y_train)\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 6) Obtener features seleccionados (CORREGIDO)\n",
    "    # ----------------------------------------------------------\n",
    "    selected_features = mrmr_sel.get_feature_names_out()  # YA NO SE USA .tolist()\n",
    "    \n",
    "    print(\"\\nFeatures seleccionados por mRMR:\")\n",
    "    print(selected_features)\n",
    "    \n",
    "    # Transformar matrices\n",
    "    X_train_mrmr = mrmr_sel.transform(X_train)\n",
    "    X_test_mrmr  = mrmr_sel.transform(X_test)\n",
    "    \n",
    "    print(\"Forma X_train_mrmr:\", X_train_mrmr.shape)\n",
    "    print(\"Forma X_test_mrmr:\", X_test_mrmr.shape)\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 7) Retornar todo lo útil\n",
    "    # ----------------------------------------------------------\n",
    "    return {\n",
    "        \"X_train_mrmr\": X_train_mrmr,\n",
    "        \"X_test_mrmr\": X_test_mrmr,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test,\n",
    "        \"selected_features\": selected_features,\n",
    "        \"mrmr_object\": mrmr_sel\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc6870",
   "metadata": {},
   "source": [
    "PARA IDDSI 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ccb06b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma original de X: (77, 161)\n",
      "Primeros nombres de columnas renombradas: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "Forma X_sig (solo significativos): (77, 50)\n",
      "Train: (53, 50)  Test: (24, 50)\n",
      "\n",
      "Features seleccionados por mRMR:\n",
      "['117', '111', '61', '123', '67', '55', '138', '144', '26', '150', '156', '71', '38', '94', '35']\n",
      "Forma X_train_mrmr: (53, 15)\n",
      "Forma X_test_mrmr: (24, 15)\n"
     ]
    }
   ],
   "source": [
    "resultado_iddsi0 = procesar_iddsi_mrmr(\n",
    "    nombre_archivo_matriz=\"IDDSI0_minmax.xlsx\",\n",
    "    sig_features_ids=sig_0,\n",
    "    max_features=15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25bf0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_train_mrmr = resultado_iddsi0[\"X_train_mrmr\"]\n",
    "X0_test_mrmr  = resultado_iddsi0[\"X_test_mrmr\"]\n",
    "y0_train      = resultado_iddsi0[\"y_train\"]\n",
    "y0_test       = resultado_iddsi0[\"y_test\"]\n",
    "features_0    = resultado_iddsi0[\"selected_features\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eb1941",
   "metadata": {},
   "source": [
    "IDDSI 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60a68ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma original de X: (84, 161)\n",
      "Primeros nombres de columnas renombradas: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "Forma X_sig (solo significativos): (84, 67)\n",
      "Train: (58, 67)  Test: (26, 67)\n",
      "\n",
      "Features seleccionados por mRMR:\n",
      "['144', '138', '35', '45', '34', '61', '29', '25', '55', '40', '158', '67', '131', '7', '8']\n",
      "Forma X_train_mrmr: (58, 15)\n",
      "Forma X_test_mrmr: (26, 15)\n"
     ]
    }
   ],
   "source": [
    "resultado_iddsi2 = procesar_iddsi_mrmr(\n",
    "    nombre_archivo_matriz=\"IDDSI2_minmax.xlsx\",  # tu archivo de matriz IDDSI 2\n",
    "    sig_features_ids=sig_2,                      # lista de features significativos RankSum\n",
    "    max_features=15                               # puedes usar 10, 15, 20, 30...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c415bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train_mrmr = resultado_iddsi2[\"X_train_mrmr\"]\n",
    "X2_test_mrmr  = resultado_iddsi2[\"X_test_mrmr\"]\n",
    "y2_train      = resultado_iddsi2[\"y_train\"]\n",
    "y2_test       = resultado_iddsi2[\"y_test\"]\n",
    "features_2    = resultado_iddsi2[\"selected_features\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ac37d4",
   "metadata": {},
   "source": [
    "IDDSI 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3366e770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma original de X: (83, 161)\n",
      "Primeros nombres de columnas renombradas: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "Forma X_sig (solo significativos): (83, 64)\n",
      "Train: (58, 64)  Test: (25, 64)\n",
      "\n",
      "Features seleccionados por mRMR:\n",
      "['16', '123', '35', '117', '24', '111', '2', '33', '34', '30', '27', '94', '131', '40', '41']\n",
      "Forma X_train_mrmr: (58, 15)\n",
      "Forma X_test_mrmr: (25, 15)\n"
     ]
    }
   ],
   "source": [
    "resultado_iddsi4 = procesar_iddsi_mrmr(\n",
    "    nombre_archivo_matriz=\"IDDSI4_minmax.xlsx\",   # tu matriz normalizada IDDSI 4\n",
    "    sig_features_ids=sig_4,                       # los features significativos del RankSum\n",
    "    max_features=15                                # puedes cambiar 10, 15, 20, etc.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dafccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train_mrmr = resultado_iddsi4[\"X_train_mrmr\"]\n",
    "X4_test_mrmr  = resultado_iddsi4[\"X_test_mrmr\"]\n",
    "y4_train      = resultado_iddsi4[\"y_train\"]\n",
    "y4_test       = resultado_iddsi4[\"y_test\"]\n",
    "features_4    = resultado_iddsi4[\"selected_features\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
